<!DOCTYPE html>
<html lang="en">
<head>
	<title>Using deep RNN to model source code</title>
	<meta charset="utf-8">
	<meta http-equiv="x-ua-compatible" content="ie=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="shower/themes/ribbon/styles/screen-16x10.css">
	<link rel="stylesheet" href="node_modules/font-awesome/css/font-awesome.min.css">
	<style>
		.fa {
			font-style: normal !important;
		}
		.noaline {
			background: none !important;
		}
	</style>
</head>
<body class="shower list">
	<header class="caption">
		<h1>Using deep RNN to model source code</h1>
		<p>Eiso Kant, <a href="http://sourced.tech">source{d}</a></p>
	</header>
	<section class="slide atom" id="cover" >
		<h2>Using deep RNN to model source code</h2>
		<p>Eiso Kant, <a href="http://sourced.tech">source{d}</a></p>
		<img src="pictures/cover.png" alt="" class="cover">
		<style>
		  .slide::after {
				display: none;
			}
		  #cover a {
				background: none !important;
			}
			.atom {
				background-color: #282c34;
				color: #FFF;
			}
			.atom h2 {
				color: #FFF;
			}
			#cover h2 {
				margin:30px 0 0;
				color: #FFF;
				text-align:center;
				font-size:70px;
			}
			#cover p {
				margin:10px 0 0;
				text-align:center;
				font-style:italic;
				font-size:20px;
			}
	    #cover p a {
		    color: #FFF;
	    }
		</style>
	</section>
	<section class="slide">
		<h2>Plan</h2>
		<div id="qrcode">
			<img src="pictures/qrcode.svg">
			<a class="noaline" href="https://goo.gl/wRQCLS">goo.gl/wRQCLS</a>
			<div>(view this on your device)</div>
		</div>
		<ol>
			<li>Motivation</li>
			<li>Source code feature engineering</li>
			<li>Network architecture</li>
			<li>Results</li>
			<li>Other work</li>
		</ol>
		<style>
			#qrcode {
				float: right;
				display: flex;
				flex-direction: column;
			}
			#qrcode > a {
				text-align: center;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Motivation</h2>
		<blockquote>Everything is better with clusters.</blockquote>
		<img id="motivation" src="pictures/motivation.png">
		<style>
			#motivation {
				height: 360px;
				margin-left: auto;
				margin-right: auto;
				display: table;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Motivation</h2>
		<p>Customers buy goods, and software developers write code.</p>
		<div id="compiling">
			<img class="cstretch" src="pictures/compiling.svg">
			<img src="pictures/arrow.png">
			<img class="cstretch" src="pictures/cproj.png">
		</div>
		<style>
			#compiling {
				height: 340px;
				display: flex;
				align-items: center;
                justify-content: center;
			}
			.cstretch {
				height: 340px;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Motivation</h2>
		<p>So to understand the latter, we need to understand what and how they
			do what they do. Feature origins:</p>
		<ul class="double">
			<li>Social networks</li>
			<li>Version control statistics
				<ul>
					<li>History</li>
					<li>Style</li>
				</ul>
			</li>
			<li>Source code
				<ul>
					<li>Algorithms</li>
					<li>Dependency graph</li>
					<li><span class="selection">Style</span></li>
				</ul>
			</li>
		</ul>
		<style>
			.selection {
			  background: linear-gradient(to top, red .19em,transparent .19em) repeat-x;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Motivation</h2>
		<img id="stylecorr" src="pictures/stylecorr.png">
		<style>
			#stylecorr {
				margin-left: auto;
				margin-right: auto;
				display: table;
				height: 400px;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Feature engineering</h2>
		<p>Requirements:</p>
		<ol>
			<li>Ignore text files, Markdown, etc.</li>
			<li>Ignore autogenerated files</li>
			<li>Support many languages with minimal efforts</li>
			<li>Include as much information about the source code as possible</li>
		</ol>
	</section>
	<section class="slide">
		<h2>Feature engineering</h2>
		<p>(1) and (2) are solved by <i class="fa fa-github"></i>
			<a href="https://github.com/github/linguist">github/linguist</a></p>
		<p>...source{d} has it's own which feels the same but works 10x faster</p>
		<ul>
			<li>Used by GihHub for language bars</li>
			<li>Supports 400+ languages</li>
		</ul>
		<a class="noaline" href="https://en.wikipedia.org/wiki/Remember_the_Name">
			<img id="github-stats" src="pictures/github_stats.png">
		</a>
		<style>
			#github-stats {
				width: 800px;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Feature engineering</h2>
		<p>(3) and (4) are solved by <a class="noaline" href="http://pygments.org/">
			<img id="pygments" src="pictures/pygments.png"></a></p>
		<ul>
			<li>Highlights source code (tokenizer)</li>
			<li>Supports 400+ languages (though only 50% intersects with
				github/linguist)</li>
			<li>≈90 token types (not all are used for every language)</li>
		</ul>
		<style>
			#pygments {
				height: 40px;
				margin-bottom: -12px;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Feature engineering</h2>
		<p>Pygments example:</p>
		<div class="double">
			<pre><code># prints "Hello, World!"</code>
<code>if True:</code>
<code>    print("Hello, World!")</code></pre>
			<div class="highlight"><pre><span></span><span class="c1"># prints &quot;Hello, World!&quot;</span>
<span class="k">if</span> <span class="bp">True</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Hello, World!&quot;</span><span class="p">)</span></pre></div>
		</div>
		<style>
			.highlight pre {
				white-space: pre;
				line-height: 2;
				font-family: PT Mono,monospace,monospace;
			}
			.highlight .c1 {
				color: #969896;
			}
			.highlight .k {
				color: #a71d5d;
			}
			.highlight .bp {
				color: #0086b3;
			}
			.highlight .s2 {
				color: #183691;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Feature engineering</h2>
		<pre id="raw-pygments">
<code>Token.Comment.Single	'# prints "Hello, World!"'</code>
<code>Token.Text	'\n'</code>
<code>Token.Keyword	'if'</code>
<code>Token.Text	' '</code>
<code>Token.Name.Builtin.Pseudo	'True'</code>
<code>Token.Punctuation	':'</code>
<code>Token.Text	'\n'</code>
<code>Token.Text	'    '</code>
<code>Token.Keyword	'print'</code>
<code>Token.Punctuation	'('</code>
<code>Token.Literal.String.Double	'"'</code>
<code>Token.Literal.String.Double	'Hello, World!'</code>
<code>Token.Literal.String.Double	'"'</code>
<code>Token.Punctuation	')'</code>
<code>Token.Text	'\n'</code>
		</pre>
		<style>
			#raw-pygments code {
				line-height: 1.1;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Feature engineering</h2>
		<img src="pictures/one_against_all.png">
	</section>
	<section class="slide">
		<h2>Feature engineering</h2>
		<ul>
			<li>Split stream into lines, each line contains ≤40 tokens</li>
			<li>Merge indents</li>
			<li>One-hot encoding with variable magnitude</li>
			<li>Some tokens occupy more than 1 dimension, e.g.
				Token.Name reflects naming style</li>
			<li>≈200 dimensions overall</li>
			<li>8000 features per line, most are zeros</li>
			<li>Mean-dispersion normalization</li>
		</ul>
	</section>
	<section id="slide-code" class="slide">
		<h2>Feature engineering</h2>
		<img src="pictures/code_all.png">
		<style>
			#slide-code {
				background: black;
			}
			#slide-code > img {
				height: 400px;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Feature engineering</h2>
		<p>Though extracted, names as words may <em>not</em> used in this scheme.</p>
		<p>We've checked out two approaches to using this extra information:</p>
		<ol>
			<li>LSTM sequence modelling (the topic of this talk)</li>
			<li>ARTM topic modelling (article is pending in our blog)</li>
		</ol>
		<img id="bag" src="pictures/bag.png">
		<style>
			#bag {
				height: 220px;
				right: 80px;
				bottom: 50px;
				position: absolute;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Network architecture</h2>
		<p>Idea: apply NLP-style LSTM to Python source code.</p>
		<p>We will experiment with <a href="https://github.com/django/django">Django</a>.</p>
		<p>Parse the code into tokens with Pygments and treat each as a word.</p>
		<p>Comments, strings should be squashed - we do not want NLP inside our NLP.</p>
		<img id="yo-dawg" src="pictures/yo_dawg.png">
		<style>
		#yo-dawg {
			position: absolute;
			right: 0px;
			bottom: -20px;
			height: 200px;
		}
		</style>
	</section>
	<section class="slide atom" id="lstm_explain">
		<h2>Network architecture</h2>
		<br><br><br><br><br>
		<pre>
			<code>{ "if": 1, "self": 2, ".": 3, "active": 4,  "(": 5, ")": 6,</code>
<code>  "and": 7,  "Weather": 8, "raining": 9, "\n": 10,</code>
<code>  "open_umbrella": 11, "*": 12, "hands": 13 }</code>
		</pre>
		<style>
		#lstm_explain {
			background-image: url("pictures/lstm_explain.png");
			background-size: contain;
			background-repeat: no-repeat;
			background-position: center;
		}
		#lstm_explain code:before {
			display: none;
		}
		</style>
	</section>
	<section class="slide">
		<h2>Network architecture</h2>
		<p>Model from "Recurrent Neural Network Regularization" by Zaremba et al. ([arXiv](http://arxiv.org/abs/1409.2329))</p>
		<img id="lstm" src="pictures/lstm.png">
		<style>
		#lstm {
			display: table;
			margin-left: auto;
			margin-right: auto;
			height: 300px;
		}
		</style>
	</section>
	<section class="slide">
		<h2>Network architecture</h2>
		<ul>
			<li>First layer: <a href="https://www.tensorflow.org/versions/r0.9/api_docs/python/rnn_cell.html#BasicLSTMCell">tf.nn.rnn_cell.BasicLSTMCell</a></li>
			<li>Dropout does not improve the perplexity in our case so is not used</li>
			<li>Second layer: <a href="https://www.tensorflow.org/versions/r0.9/api_docs/python/rnn_cell.html#MultiRNNCell">tf.nn.rnn_cell.MultiRNNCell</a></li>
			<li>Softmax sequence loss</li>
		</ul>
	</section>
	<section class="slide">
		<h2>Network architecture</h2>
		<table>
			<tbody>
			<tr>
				<th scope="row">Optimizer</th>
				<td>GD with clipping to 5.0</td>
			</tr>
			<tr>
				<th scope="row">Learning rate</th>
				<td>1.0</td>
			</tr>
			<tr>
				<th scope="row">Weight decay</th>
				<td>0.5 after 4 epochs</td>
			</tr>
			<tr>
				<th scope="row">History size</th>
				<td>20</td>
			</tr>
			<tr>
				<th>First layer size</th>
				<td>200</td>
			</tr>
			</tbody>
		</table>
	</section>
	<section class="slide">
		<h2>Network architecture</h2>
		Implementation:
		<ul>
			<li>Python3 / Tensorflow / NVIDIA GPU</li>
			<li>Really slow even with GPU (1 hour to complete 13 epochs)</li>
			<li>Interactive forward prop app</li>
		</ul>
	</section>
	<section class="slide">
		<h2>Results</h2>
		<ul>
			<li>Perplexity is extremely low: &lt; 3 (on PTB dataset you get 100)</li>
			<li>The network predicts the first 1-3 tokens that exactly the programmer wants to write</li>
			<li>After first 1-3 tokens a fantasy starts</li>
			<li>The more the project is homogeneous, the better looks the fantasy</li>
		</ul>
	</section>
	<section class="slide atom" id="showcase">
		<h2>Results</h2>
		<ul>
      <li><div>Before:</div><img id="cbefore" src="pictures/completion_before.png"></li>
		  <li><div>After:</div><img id="cafter" src="pictures/completion_after.png"></li>
	  </ul>
		<style>
		#showcase li {
			display: flex;
			justify-content: center;
			align-items: center;
			margin-bottom: 10px;
		}
		#showcase li > div {
			width: 100px;
		}
		#showcase li:before {
			display: none;
		}
		</style>
	</section>
	<section class="slide">
		<h2>Results</h2>
		Can be useful for
		<ul>
			<li>Next-gen intelligent code completion which adapts to the project being developed</li>
			<li>Coupled with CNN on higher levels the network can turn abstract algorithms expressed with a natural language into source code</li>
			<li>Self-programming AI</li>
			<li>...and source{d} uses it only to embed the features</li>
		</ul>
		<img id="terminator" src="pictures/terminator.jpg">
		<style>
		#terminator {
			position: absolute;
			right: -35px;
			bottom: -35px;
			width: 250px;
			transform: rotate(-45deg);
		}
		</style>
	</section>
	<section class="slide">
		<h2>Other work - KMeans for devs clustering</h2>
        <img id="github-clusters" src="pictures/github_clusters.png">
				<a id="kmcuda" href="https://github.com/src-d/kmcuda">src-d/kmcuda</a>
		<style>
			#github-clusters {
				height: 450px;
				display: table;
				margin-right: auto;
				margin-left: auto;
			}
			#kmcuda {
				position: absolute;
				right: 80px;
				bottom: 50px;
			}
		</style>
	</section>
	<section class="slide">
		<h2>Other work - CNN for code classification</h2>
   <ul>
		 <li>Classify source code abstracts between 2 different projects</li>
		 <li>Presented at RE·WORK in Berlin (June 2016)</li>
		 <li>50% copied to here</li>
		 <li><a href="https://goo.gl/4zq8g9">Slides</a></li>
	 </ul>
	</section>
	<section class="slide">
		<h2>Thank you</h2>
		<p style="color: #585a5e">We are hiring!</p>
		<img src="pictures/dream_code.jpg" class="cover">
	</section>
	<p class="badge">
		<a href="mailto://eiso@sourced.tech">We are hiring!</a>
	</p>
	<div class="progress"></div>
	<script src="shower/shower.min.js"></script>
</body>
</html>
